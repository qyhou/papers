# Transformer
- [Shunted Self-Attention via Multi-Scale Token Aggregation](https://arxiv.org/abs/2111.15193), (NUS, SCUT, ByteDance), CVPR-2022
- ```Swin Transformer V2``` [Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/abs/2111.09883v2), (Microsoft), CVPR-2022
- ```Swin Transformer``` [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030v2), (Microsoft), ICCV-2021
- ```ViT``` [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929), (Google), ICLR-2021

# CNN
- ```GhostNetV2``` [GhostNetV2: Enhance Cheap Operation with Long-Range Attention](https://arxiv.org/abs/2211.12905), (PKU, Huawei, USYD), NeurIPS-2022
- ```EfficientNetV2``` [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298), (Google), ICML-2021
- ```GhostNet``` [GhostNet: More Features from Cheap Operations](https://arxiv.org/abs/1911.11907), (Huawei, PKU, USYD), CVPR-2020
- ```EfficientNet``` [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946), (Google), ICML-2019
- ```MobileNetV3``` [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244), (Google), ICCV-2019
- ```FBNet``` [FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search](https://arxiv.org/abs/1812.03443), (UC Berkeley, Princeton, Facebook), CVPR-2019
- ```ResNet-B/C/D``` [Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/abs/1812.01187), (Amazon), CVPR-2019
- ```ShuffleNet V2``` [ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design](https://arxiv.org/abs/1807.11164), (Megvii, Tsinghua), ECCV-2018
- ```MobileNetV2``` [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381), (Google), CVPR-2018
- ```NASNet``` [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012), (Google), CVPR-2018
- ```ShuffleNet``` [ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices](https://arxiv.org/abs/1707.01083), (Megvii), CVPR-2018
- [Dilated Residual Networks](https://arxiv.org/abs/1705.09914), (Princeton, Intel), CVPR-2017
- ```MobileNet``` [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861), (Google)
- [Deformable Convolutional Networks](https://arxiv.org/abs/1703.06211), (Microsoft), ICCV-2017
- ```FPN``` [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144), (Facebook, Cornell), CVPR-2017
- ```DenseNet``` [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993), (Cornell, Tsinghua, Facebook), CVPR-2017
- ```SqueezeNet``` [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size](https://arxiv.org/abs/1602.07360), (DeepScale, UC Berkeley, Stanford), ICLR-2017
- ```ResNet``` [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385), (Microsoft), CVPR-2016
- [Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122), (Princeton, Intel), ICLR-2016
- ```VGG``` [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556), (Oxford), ICLR-2015
